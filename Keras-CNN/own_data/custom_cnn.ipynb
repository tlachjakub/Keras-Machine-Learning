{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named cv2",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-524efeea6a61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \"\"\"\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Import libraries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named cv2"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Created on Thu May  4 23:32:34 2017\n",
    "@author: anuj shah\n",
    "\"\"\"\n",
    "# Import libraries\n",
    "import os, cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('tf')\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD,RMSprop,adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "PATH = os.getcwd()\n",
    "# Define data path\n",
    "data_path = PATH + '/data'\n",
    "data_dir_list = os.listdir(data_path)\n",
    "\n",
    "img_rows=128\n",
    "img_cols=128\n",
    "num_channel=1\n",
    "num_epoch=20\n",
    "\n",
    "# Define the number of classes\n",
    "num_classes = 4\n",
    "\n",
    "img_data_list=[]\n",
    "\n",
    "for dataset in data_dir_list:\n",
    "\timg_list=os.listdir(data_path+'/'+ dataset)\n",
    "\tprint ('Loaded the images of dataset-'+'{}\\n'.format(dataset))\n",
    "\tfor img in img_list:\n",
    "\t\tinput_img=cv2.imread(data_path + '/'+ dataset + '/'+ img )\n",
    "\t\tinput_img=cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)\n",
    "\t\tinput_img_resize=cv2.resize(input_img,(128,128))\n",
    "\t\timg_data_list.append(input_img_resize)\n",
    "\n",
    "img_data = np.array(img_data_list)\n",
    "img_data = img_data.astype('float32')\n",
    "img_data /= 255\n",
    "print (img_data.shape)\n",
    "\n",
    "if num_channel==1:\n",
    "\tif K.image_dim_ordering()=='th':\n",
    "\t\timg_data= np.expand_dims(img_data, axis=1) \n",
    "\t\tprint (img_data.shape)\n",
    "\telse:\n",
    "\t\timg_data= np.expand_dims(img_data, axis=4) \n",
    "\t\tprint (img_data.shape)\n",
    "\t\t\n",
    "else:\n",
    "\tif K.image_dim_ordering()=='th':\n",
    "\t\timg_data=np.rollaxis(img_data,3,1)\n",
    "\t\tprint (img_data.shape)\n",
    "\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "USE_SKLEARN_PREPROCESSING=False\n",
    "\n",
    "if USE_SKLEARN_PREPROCESSING:\n",
    "\t# using sklearn for preprocessing\n",
    "\tfrom sklearn import preprocessing\n",
    "\t\n",
    "\tdef image_to_feature_vector(image, size=(128, 128)):\n",
    "\t\t# resize the image to a fixed size, then flatten the image into\n",
    "\t\t# a list of raw pixel intensities\n",
    "\t\treturn cv2.resize(image, size).flatten()\n",
    "\t\n",
    "\timg_data_list=[]\n",
    "\tfor dataset in data_dir_list:\n",
    "\t\timg_list=os.listdir(data_path+'/'+ dataset)\n",
    "\t\tprint ('Loaded the images of dataset-'+'{}\\n'.format(dataset))\n",
    "\t\tfor img in img_list:\n",
    "\t\t\tinput_img=cv2.imread(data_path + '/'+ dataset + '/'+ img )\n",
    "\t\t\tinput_img=cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)\n",
    "\t\t\tinput_img_flatten=image_to_feature_vector(input_img,(128,128))\n",
    "\t\t\timg_data_list.append(input_img_flatten)\n",
    "\t\n",
    "\timg_data = np.array(img_data_list)\n",
    "\timg_data = img_data.astype('float32')\n",
    "\tprint (img_data.shape)\n",
    "\timg_data_scaled = preprocessing.scale(img_data)\n",
    "\tprint (img_data_scaled.shape)\n",
    "\t\n",
    "\tprint (np.mean(img_data_scaled))\n",
    "\tprint (np.std(img_data_scaled))\n",
    "\t\n",
    "\tprint (img_data_scaled.mean(axis=0))\n",
    "\tprint (img_data_scaled.std(axis=0))\n",
    "\t\n",
    "\tif K.image_dim_ordering()=='th':\n",
    "\t\timg_data_scaled=img_data_scaled.reshape(img_data.shape[0],num_channel,img_rows,img_cols)\n",
    "\t\tprint (img_data_scaled.shape)\n",
    "\t\t\n",
    "\telse:\n",
    "\t\timg_data_scaled=img_data_scaled.reshape(img_data.shape[0],img_rows,img_cols,num_channel)\n",
    "\t\tprint (img_data_scaled.shape)\n",
    "\t\n",
    "\t\n",
    "\tif K.image_dim_ordering()=='th':\n",
    "\t\timg_data_scaled=img_data_scaled.reshape(img_data.shape[0],num_channel,img_rows,img_cols)\n",
    "\t\tprint (img_data_scaled.shape)\n",
    "\t\t\n",
    "\telse:\n",
    "\t\timg_data_scaled=img_data_scaled.reshape(img_data.shape[0],img_rows,img_cols,num_channel)\n",
    "\t\tprint (img_data_scaled.shape)\n",
    "\n",
    "if USE_SKLEARN_PREPROCESSING:\n",
    "\timg_data=img_data_scaled\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Assigning Labels\n",
    "\n",
    "# Define the number of classes\n",
    "num_classes = 4\n",
    "\n",
    "num_of_samples = img_data.shape[0]\n",
    "labels = np.ones((num_of_samples,),dtype='int64')\n",
    "\n",
    "labels[0:202]=0\n",
    "labels[202:404]=1\n",
    "labels[404:606]=2\n",
    "labels[606:]=3\n",
    "\t  \n",
    "names = ['cats','dogs','horses','humans']\n",
    "\t  \n",
    "# convert class labels to on-hot encoding\n",
    "Y = np_utils.to_categorical(labels, num_classes)\n",
    "\n",
    "#Shuffle the dataset\n",
    "x,y = shuffle(img_data,Y, random_state=2)\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Defining the model\n",
    "input_shape=img_data[0].shape\n",
    "\t\t\t\t\t\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(32, 3,3,border_mode='same',input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(32, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Convolution2D(64, 3, 3))\n",
    "#model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "#sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "#model.compile(loss='categorical_crossentropy', optimizer=sgd,metrics=[\"accuracy\"])\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop',metrics=[\"accuracy\"])\n",
    "\n",
    "# Viewing model_configuration\n",
    "\n",
    "model.summary()\n",
    "model.get_config()\n",
    "model.layers[0].get_config()\n",
    "model.layers[0].input_shape\t\t\t\n",
    "model.layers[0].output_shape\t\t\t\n",
    "model.layers[0].get_weights()\n",
    "np.shape(model.layers[0].get_weights()[0])\n",
    "model.layers[0].trainable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Training\n",
    "hist = model.fit(X_train, y_train, batch_size=16, nb_epoch=num_epoch, verbose=1, validation_data=(X_test, y_test))\n",
    "\n",
    "#hist = model.fit(X_train, y_train, batch_size=32, nb_epoch=20,verbose=1, validation_split=0.2)\n",
    "\n",
    "# Training with callbacks\n",
    "from keras import callbacks\n",
    "\n",
    "filename='model_train_new.csv'\n",
    "csv_log=callbacks.CSVLogger(filename, separator=',', append=False)\n",
    "\n",
    "early_stopping=callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='min')\n",
    "\n",
    "filepath=\"Best-weights-my_model-{epoch:03d}-{loss:.4f}-{acc:.4f}.hdf5\"\n",
    "\n",
    "checkpoint = callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "callbacks_list = [csv_log,early_stopping,checkpoint]\n",
    "\n",
    "hist = model.fit(X_train, y_train, batch_size=16, nb_epoch=num_epoch, verbose=1, validation_data=(X_test, y_test),callbacks=callbacks_list)\n",
    "\n",
    "\n",
    "# visualizing losses and accuracy\n",
    "train_loss=hist.history['loss']\n",
    "val_loss=hist.history['val_loss']\n",
    "train_acc=hist.history['acc']\n",
    "val_acc=hist.history['val_acc']\n",
    "xc=range(2)\n",
    "\n",
    "plt.figure(1,figsize=(7,5))\n",
    "plt.plot(xc,train_loss)\n",
    "plt.plot(xc,val_loss)\n",
    "plt.xlabel('num of Epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.title('train_loss vs val_loss')\n",
    "plt.grid(True)\n",
    "plt.legend(['train','val'])\n",
    "#print plt.style.available # use bmh, classic,ggplot for big pictures\n",
    "plt.style.use(['classic'])\n",
    "\n",
    "plt.figure(2,figsize=(7,5))\n",
    "plt.plot(xc,train_acc)\n",
    "plt.plot(xc,val_acc)\n",
    "plt.xlabel('num of Epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('train_acc vs val_acc')\n",
    "plt.grid(True)\n",
    "plt.legend(['train','val'],loc=4)\n",
    "#print plt.style.available # use bmh, classic,ggplot for big pictures\n",
    "plt.style.use(['classic'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Evaluating the model\n",
    "\n",
    "score = model.evaluate(X_test, y_test, show_accuracy=True, verbose=0)\n",
    "print('Test Loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "test_image = X_test[0:1]\n",
    "print (test_image.shape)\n",
    "\n",
    "print(model.predict(test_image))\n",
    "print(model.predict_classes(test_image))\n",
    "print(y_test[0:1])\n",
    "\n",
    "# Testing a new image\n",
    "test_image = cv2.imread('data/Humans/rider-8.jpg')\n",
    "test_image=cv2.cvtColor(test_image, cv2.COLOR_BGR2GRAY)\n",
    "test_image=cv2.resize(test_image,(128,128))\n",
    "test_image = np.array(test_image)\n",
    "test_image = test_image.astype('float32')\n",
    "test_image /= 255\n",
    "print (test_image.shape)\n",
    "   \n",
    "if num_channel==1:\n",
    "\tif K.image_dim_ordering()=='th':\n",
    "\t\ttest_image= np.expand_dims(test_image, axis=0)\n",
    "\t\ttest_image= np.expand_dims(test_image, axis=0)\n",
    "\t\tprint (test_image.shape)\n",
    "\telse:\n",
    "\t\ttest_image= np.expand_dims(test_image, axis=3) \n",
    "\t\ttest_image= np.expand_dims(test_image, axis=0)\n",
    "\t\tprint (test_image.shape)\n",
    "\t\t\n",
    "else:\n",
    "\tif K.image_dim_ordering()=='th':\n",
    "\t\ttest_image=np.rollaxis(test_image,2,0)\n",
    "\t\ttest_image= np.expand_dims(test_image, axis=0)\n",
    "\t\tprint (test_image.shape)\n",
    "\telse:\n",
    "\t\ttest_image= np.expand_dims(test_image, axis=0)\n",
    "\t\tprint (test_image.shape)\n",
    "\t\t\n",
    "# Predicting the test image\n",
    "print((model.predict(test_image)))\n",
    "print(model.predict_classes(test_image))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Visualizing the intermediate layer\n",
    "\n",
    "#\n",
    "def get_featuremaps(model, layer_idx, X_batch):\n",
    "\tget_activations = K.function([model.layers[0].input, K.learning_phase()],[model.layers[layer_idx].output,])\n",
    "\tactivations = get_activations([X_batch,0])\n",
    "\treturn activations\n",
    "\n",
    "layer_num=3\n",
    "filter_num=0\n",
    "\n",
    "activations = get_featuremaps(model, int(layer_num),test_image)\n",
    "\n",
    "print (np.shape(activations))\n",
    "feature_maps = activations[0][0]      \n",
    "print (np.shape(feature_maps))\n",
    "\n",
    "if K.image_dim_ordering()=='th':\n",
    "\tfeature_maps=np.rollaxis((np.rollaxis(feature_maps,2,0)),2,0)\n",
    "print (feature_maps.shape)\n",
    "\n",
    "fig=plt.figure(figsize=(16,16))\n",
    "plt.imshow(feature_maps[:,:,filter_num],cmap='gray')\n",
    "plt.savefig(\"featuremaps-layer-{}\".format(layer_num) + \"-filternum-{}\".format(filter_num)+'.jpg')\n",
    "\n",
    "num_of_featuremaps=feature_maps.shape[2]\n",
    "fig=plt.figure(figsize=(16,16))\t\n",
    "plt.title(\"featuremaps-layer-{}\".format(layer_num))\n",
    "subplot_num=int(np.ceil(np.sqrt(num_of_featuremaps)))\n",
    "for i in range(int(num_of_featuremaps)):\n",
    "\tax = fig.add_subplot(subplot_num, subplot_num, i+1)\n",
    "\t#ax.imshow(output_image[0,:,:,i],interpolation='nearest' ) #to see the first filter\n",
    "\tax.imshow(feature_maps[:,:,i],cmap='gray')\n",
    "\tplt.xticks([])\n",
    "\tplt.yticks([])\n",
    "\tplt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig(\"featuremaps-layer-{}\".format(layer_num) + '.jpg')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Printing the confusion matrix\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import itertools\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "print(Y_pred)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print(y_pred)\n",
    "#y_pred = model.predict_classes(X_test)\n",
    "#print(y_pred)\n",
    "target_names = ['class 0(cats)', 'class 1(Dogs)', 'class 2(Horses)','class 3(Humans)']\n",
    "\t\t\t\t\t\n",
    "print(classification_report(np.argmax(y_test,axis=1), y_pred,target_names=target_names))\n",
    "\n",
    "print(confusion_matrix(np.argmax(y_test,axis=1), y_pred))\n",
    "\n",
    "\n",
    "# Plotting the confusion matrix\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = (confusion_matrix(np.argmax(y_test,axis=1), y_pred))\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plot_confusion_matrix(cnf_matrix, classes=target_names,\n",
    "                      title='Confusion matrix')\n",
    "#plt.figure()\n",
    "# Plot normalized confusion matrix\n",
    "#plot_confusion_matrix(cnf_matrix, classes=target_names, normalize=True,\n",
    "#                      title='Normalized confusion matrix')\n",
    "#plt.figure()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Saving and loading model and weights\n",
    "from keras.models import model_from_json\n",
    "from keras.models import load_model\n",
    "\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "# load json and create model\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "model.save('model.hdf5')\n",
    "loaded_model=load_model('model.hdf5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
